{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "vDDgl7iIpNxK"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from keras.callbacks import Callback\n",
    "from keras.backend import clear_session\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Dense, Input, Flatten\n",
    "from keras.applications import ResNet50, MobileNet, Xception, DenseNet121\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "ibnkUMMupk0W"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UUmIVCzfpnuM",
    "outputId": "9929e9af-09f6-40f3-a2d2-c53fad093f30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CU5kNO4PpqFq"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "from tensorflow.keras.models import Sequential as seq\n",
    "from tensorflow.keras.layers import Dense, Activation, Conv2D, Flatten, Dropout, MaxPooling2D, BatchNormalization\n",
    "from keras.layers import AveragePooling2D\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras import regularizers, optimizers\n",
    "\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "def mean_pred(y_true, y_pred):\n",
    "    return K.mean(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N8tNlq6B9gki"
   },
   "source": [
    "# Data Loader\n",
    "The Notebook has been executed on google colab so we mount the drive and use the data from the drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9e5zNVzXtnvY",
    "outputId": "3b3968fa-113d-49f6-d157-94db386eee04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             ImageId                 ClassName\n",
      "0     f27632d7e5.jpg                     water\n",
      "1     efa87919ed.jpg    pizza-margherita-baked\n",
      "2     4f169e8c8d.jpg                  broccoli\n",
      "3     a6956654bf.jpg    salad-leaf-salad-green\n",
      "4     d99ce8c3bf.jpg                       egg\n",
      "...              ...                       ...\n",
      "9318  ba8233c7d2.jpg  bread-french-white-flour\n",
      "9319  2090043907.jpg                  wine-red\n",
      "9320  8762d1cefd.jpg                    carrot\n",
      "9321  28e7439245.jpg                  broccoli\n",
      "9322  ba263cfb41.jpg                  cucumber\n",
      "\n",
      "[9323 rows x 2 columns]\n",
      "61\n",
      "#############################################################################################9323\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_path='/content/drive/MyDrive/test_images'\n",
    "trainpath='/content/drive/MyDrive/train_images'\n",
    "train_cpath='/content/drive/MyDrive/train.csv'\n",
    "test_cpath='/content/drive/MyDrive/test.csv'\n",
    "df = pd.read_csv(train_cpath)  \n",
    "df_test = pd.read_csv(test_cpath)\n",
    "print(df)\n",
    "classes = list(np.unique(df['ClassName']))\n",
    "print(len(classes))\n",
    "classDict = {}\n",
    "for i in range(61):\n",
    "    classDict[classes[i]]=i\n",
    "imgIdsList=df['ImageId']\n",
    "clsNameList=df['ClassName']\n",
    "trial_label={}\n",
    "for i in range(len(df)):\n",
    "    trial_label[imgIdsList[i]]=classDict[clsNameList[i]]\n",
    "X = []\n",
    "Y = []\n",
    "l=0\n",
    "for imgName,clsID in trial_label.items():\n",
    "    currImagePath=os.path.join(trainpath,imgName)\n",
    "    img=cv2.imread(currImagePath)\n",
    "    img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    resized=cv2.resize(img,(150,150))\n",
    "    X.append(resized)\n",
    "    Y.append(clsID)\n",
    "    l+=1\n",
    "    if(l%100==0):\n",
    "      print('#',end='')\n",
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7EVWDsI-a-cB",
    "outputId": "1890e1f4-3797-4ff1-bec4-5912c13ceaaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9323\n"
     ]
    }
   ],
   "source": [
    "print(len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GToUKGUyuQ6p",
    "outputId": "0ec87e12-083b-4a37-dc02-3fa4719f435d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9323, 150, 150, 3)\n",
      "6526\n"
     ]
    }
   ],
   "source": [
    "X=np.asarray(X,'float')\n",
    "print(X.shape)\n",
    "Y_array=np.array(Y)\n",
    "X_train,X_val,y_train,y_val=train_test_split(X,Y_array,test_size=0.30,random_state=2)\n",
    "print(len(y_train))\n",
    "## Normalization\n",
    "\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_val = X_val.astype(np.float32)\n",
    "\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_val = y_val.astype(np.float32)\n",
    "\n",
    "MEAN = np.mean(X_train, axis = (0,1,2))\n",
    "STD = np.std(X_train, axis = (0,1,2))\n",
    "\n",
    "#for i in range(3):\n",
    " #   X_train[:, :, :, i] = (X_train[:, :, :, i] - MEAN[i]) / STD[i]\n",
    "  #  X_val[:, :, :, i] = (X_val[:, :, :, i] - MEAN[i]) / STD[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "YChSC9-6F-cP"
   },
   "outputs": [],
   "source": [
    "early_stopping_monitor = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0,\n",
    "    patience=0,\n",
    "    verbose=0,\n",
    "    mode='auto',\n",
    "    baseline=None,\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gb9EyixA9udd"
   },
   "source": [
    "# Model\n",
    "The models experimented are DenseNet121,MobileNet, Xception or ResNet50. Xception outperformed in this problem's case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "If55rHAivJWu",
    "outputId": "a007a2f4-d6b2-4ef2-8b73-0f14816a80a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels.h5\n",
      "91889664/91884032 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "clear_session()\n",
    "img = Input(shape = (150, 150, 3))\n",
    "\n",
    "## Tried DenseNet121 , MobileNet, Xception & ResNet50\n",
    "model = Xception(include_top=True, \n",
    "                    weights='imagenet', \n",
    "                    input_tensor=img, \n",
    "                    input_shape=None, \n",
    "                    pooling='max')\n",
    "final_layer = model.layers[-1].output\n",
    "\n",
    "dense_layer_1 = Dense(128, activation = 'relu')(final_layer)\n",
    "output_layer = Dense(61, activation = 'softmax')(dense_layer_1)\n",
    "\n",
    "model = Model(img,output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SGz1KqhKwGMK",
    "outputId": "953f10bc-8972-4f10-d265-bd494dc06098"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 60/204 [=======>......................] - ETA: 40s - loss: 3.1459 - accuracy: 0.2077"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy' , metrics = ['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size = 32, epochs = 10, validation_data = (X_val, y_val),callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DgcGmGgm99k_"
   },
   "source": [
    "The test data is loaded and the model is used to predict the labesls and the labels are converted using the class dictionary obtained earlier from the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pnZN4cNnwYNa"
   },
   "outputs": [],
   "source": [
    "print(df_test)\n",
    "imgIdsList=df_test['ImageId']\n",
    "X_test = []\n",
    "l=0\n",
    "for imgName in imgIdsList:\n",
    "    currImagePath=os.path.join(test_path,imgName)\n",
    "    img=cv2.imread(currImagePath)\n",
    "    img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    resized=cv2.resize(img,(150,150))\n",
    "    X_test.append(resized)\n",
    "    l+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "RMoghR2xnPAq"
   },
   "outputs": [],
   "source": [
    "X_test=np.asarray(X_test,'float')\n",
    "#for i in range(3):\n",
    "  #X_test[:, :, :, i] = (X_test[:, :, :, i] - MEAN[i]) / STD[i]\n",
    "for i in range(61):\n",
    "    classDict[classes[i]]=i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "miwuWXOhmccL"
   },
   "outputs": [],
   "source": [
    "X_test=np.asarray(X_test,'float')\n",
    "y_test=model.predict(X_test)\n",
    "def get_key(val):\n",
    "    for key, value in classDict.items():\n",
    "         if val == value:\n",
    "             return key\n",
    " \n",
    "    return \"key doesn't exist\"\n",
    "test=np.argmax(y_test,axis=1)\n",
    "test2=[]\n",
    "for example in test:\n",
    "    test2.append(get_key(example))\n",
    "df = pd.DataFrame(test2) \n",
    "df.columns=['ClassName']    \n",
    "# saving the dataframe \n",
    "df.to_csv('GFG.csv',index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ou7fnLM5-I2q"
   },
   "source": [
    "The ClassNames for the 483 images are as shown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "aNKBe06QnoDX",
    "outputId": "cdecead2-6f33-40a2-b535-992b63837c80"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ClassName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>coffee-with-caffeine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hard-cheese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bread-wholemeal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>broccoli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>pasta-spaghetti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>bread-wholemeal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>salad-leaf-salad-green</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>484 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ClassName\n",
       "0                     water\n",
       "1                     water\n",
       "2      coffee-with-caffeine\n",
       "3               hard-cheese\n",
       "4           bread-wholemeal\n",
       "..                      ...\n",
       "479                broccoli\n",
       "480         pasta-spaghetti\n",
       "481                   water\n",
       "482         bread-wholemeal\n",
       "483  salad-leaf-salad-green\n",
       "\n",
       "[484 rows x 1 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "2018122010_Tournament_arc.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
